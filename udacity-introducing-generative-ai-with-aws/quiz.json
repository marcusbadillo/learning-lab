{
  "__title__": "Udacity Introducing Generative AI with AWS",
  "What is Artificial Intelligence (AI)?": "Refers to computers simulating human intelligence processes like learning, reasoning, self-correction, and creativity. The endeavor to equip machines with human-like information processing and decision-making capabilities.",
  "What does 'bellicose' mean?": "Demonstrating aggression and willingness to fight",
  "What is Generative AI?": "A type of AI that can create new content such as images, text, or audio by learning patterns from existing data.",
  "What is Amazon Bedrock?": "A fully managed service that makes foundation models from AI companies available via an API without managing infrastructure.",
  "What is a foundation model (FM)?": "A large AI model trained on broad data that can be adapted to many different tasks.",
  "Who or what is ELIZA?": "A computer program created in the 1960s, was one of the first programs designed to have a conversation with people.",
  "What is Human Intelligence (HI)?": " The innate ability of humans to process information and make decisions based on it.",
  "What is Machine Learning (ML)?": " A subset of AI, it involves training computers to learn from data and improve over time.",
  "What are Data Points?": "Individual pieces of information processed for decision-making.",
  "What is Certainty?": "The level of confidence in making a decision based on processed information.",
  "What us 'Data' in the context of AI development?": "The myriad forms of digital information like images, text, pixels, and numbers that fuel the learning process.",
  "What is ML Algorithm Code?": "The rulebook guiding the processing of data.",
  "What is a Machine Learning Model?": "Often dubbed as the system's 'brain', it harnesses algorithms to process data, paving the path for predictions or decisions.",
  "What is training?": "The saga of nurturing the model by processing data through the ML algorithm code.",
  "What is Testing Models?": "The act of gauging the model's mettle using new data, post-training.",
  "What is the Iteration in AI development?": "The cycle of tweaking algorithms and data, coupled with re-training, aiming to uplift model performance.",
  "What is Supervised learning?": "Like learning with a Teacher, You provide the model with data and the correct answers (labels) for each data point, much like showing a picture of a cat and telling the model it's a cat. You should use this, If you have labeled data and you want the model to learn the right answer from this data. EX, Classifying images, speech recognition, self-driving car tasks like identifying pedestrians",
  "What is Unsupervised Learning?": "A type of Model training that explores a lot of data on its own to find patterns and structures. Use this when you have unlabeled data and you want the model to find patterns or structures in the data. Ex, Generating new songs, writing code, handling unlabeled data.",
  "What is Reinforcement Learning?": "A type of model training by interacting with an environment, receiving rewards for right actions and penalties for wrong ones. Use this when you want your model to learn from its interactions and feedback, without needing labeled data.Ex, Video games, robotics, real-time decision-making in self-driving cars.",
  "What are Decision Trees? (Machine Learning)": "Flowchart-like structures aiding in decision-making based on data features.",
  "What are Regression Algorithms? (Machine Learning)": "Useful for predicting numerical values by modeling relationships between variables.",
  "What are Clustering Algorithms? (Machine Learning)": "Techniques that group data into clusters based on similarity, aiding in data segmentation and categorization.",
  "Artificial Neural Networks (Deep Learning)": "Inspired by the human brain, these networks excel in processing huge amounts of data and learning patterns from it.",
  "Convolutional Neural Networks - CNNs (Deep Learning)": "Specialized for vision tasks, preserving spatial context of images.",
  "Recurrent Neural Networks - RNNs (Deep Learning)": "Efficient for sequential data, aiding in tasks like predictive text.",
  "Generative Models (Advanced Deep Learning)": "Aim to generate new data samples similar to input data, useful in creating new content.",
  "Transformer Architecture (Advanced Deep Learning)": "Consisting of encoders and decoders, crucial in language translation and code generation tasks.",
  "What is the Training Process for Neural Networks?": "Involves feeding data through the network, adjusting weights based on errors, and iterating to improve accuracy. Unlike decision trees, neural networks are not easily visualizable in terms of their decision-making process because they are considered 'black box' models. You can plot the training and validation loss and accuracy over epochs to understand how the model is learning.",
  "What is the ReLU activation function?": "A non-linear function that helps neural networks learn complex patterns by introducing non-linearity, allowing the model to learn more complex relationships in the data.",
  "Waht is the Sigmoid activation function": "used in the output layer to produce a probability score between 0 and 1, suitable for binary classification tasks.",
  "What is an epoch?": "one complete pass through the entire training dataset during the training of a machine learning model. It is a single iteration where the model learns from all the training data once.",
  "What is an epic?": "a large, significant project or task that is part of a larger development process, often used in agile methodologies to describe a substantial feature or goal that can be broken down into smaller tasks or user stories.",
  "What are Decision Boundary (neural networks)": "a boundary in the feature space that separates the data points into different classes based on the predictions made by the model",
  "What is Binary Classification?": "A type of classification task where the model predicts one of two possible classes or outcomes, such as spam vs. not spam in email filtering.",
  "What is Multiclass classification?": "this is a type of classification task where the model predicts one of three or more possible classes or outcomes, such as classifying images into categories like cats, dogs, and birds. (predict values from a limited, predefined set of permissbable)",
  "What us a 'Reature' in machine learning?": "Is an individual measurable property or characteristic used by the model to make predictions. Features are the input variables that the model uses to learn patterns and make decisions. (determines accuracy of model predictions)",
  "What is a 'Weight' in machine learning?": "A parameter within the model that determines the importance of a feature in making predictions. These are adjusted during the training process to minimize the error in the model's predictions. (contextual wiegh, higher weight means more importance)",
  "What is Overfitting?": "A scenario where a model learns the training data too well, capturing noise and outliers, leading to poor generalization on new data. It occurs when the model is too complex relative to the amount of training data available. (eval stage doesnt perform well)",
  "Why are transformer architectures significant in the context of LLMs?": "They allow efficient processing of text and adaptable attention. They enable the model to focus on relevant parts of the input text, making them highly effective for tasks like language translation and text generation.",
  "What aspect of Large Language Models is critical for their ability to understand and generate human-like language?": "The large number of para meters they contain, which allows them to learn complex patterns and relationships in language data and extensive trained data, which enables them to understand context, grammar, and semantics effectively.",
  "Tokenization ": "Breaking down text into smaller units (tokens), such as words or phrases, for easier analysis.",
  "Parsing ": "Analyzing the grammatical structure of sentences to understand how words relate to each other.",
  "Semantic Analysis ": "Understanding the meaning behind words by considering context, synonyms, and ambiguities.",
  "Contextual Understanding ": "Utilizing the context of surrounding sentences to enhance interpretation, including understanding implied meanings and intentions.",
  "Statistical Inference": "Using probabilities to predict subsequent words or appropriate responses in a conversation.",
  "Machine Learning Integration ": "Continuously learning from new inputs to improve language prediction and understanding.",
  "Why is tokenization an important step in Natural Language Processing?": "It breaks down text into manageable pieces, allowing models to analyze and understand language more effectively. This is crucial because it transforms raw text into a format that machine learning models can process, enabling them to learn patterns and relationships in the data.",
  "How does statistical inference contribute to NLP's effectiveness?": "It allows models to predict the next word or appropriate response based on the context of the conversation, enhancing the model's ability to generate coherent and contextually relevant text. This is essential for tasks like language translation, text generation, and conversational AI, where understanding context and making accurate predictions are key.",
  "What are the three technique used in the history of evolution of LLMs ": "rules-based systems, statistical models, and deep learning (transformers) approaches. These techniques have evolved from simple rule-based systems that relied on predefined rules to more complex statistical models that analyze large datasets, and finally to deep learning approaches that utilize neural networks to learn patterns and relationships in language data.",
  "Rule-Based Systems": "Early models based on explicit grammatical and syntactic rules, limited and inflexible.",
  "Statistical Models": "Shifted to probability-based predictions, enabling more complex language processing.",
  "Machine Learning Models": "Began understanding context and patterns, but struggled with long-range dependencies.",
  "Neural Networks (RNNs and LSTMs)": "Improved handling of sequences and memory, marking significant progress.",
  "Transformer-Based Architectures": "Introduced attention mechanisms, allowing models to weigh the importance of each part of the sentence, thus capturing intricate relationships and context.",
  "How do modern LLMs differ from earlier statistical models in understanding language?": "LLMs incorporate deep learning to understand context and relationships in text.",
  "What role do neural networks, particularly RNNs and LSTMs, play in the development of LLMs?": "They improved the handling of sequences and memory, enabling models to better understand context and relationships in language data.",
  "What are Embeddings?": "numerical representations of words or tokens, typically in the form of vectors. THey convert words into a format that can be processed by neural networks and other algorithms. They capture and quantify aspects of word meanings, their use in different contexts, and their syntactic roles.",
  "What is Attention Mechanism?": "A core concept in Transformer architectures. The attention mechanism, particularly self-attention, allows the model to weigh the importance of each word in a sentence in relation to every other word.",
  "What is Context Capture in Text?": "Transformers are notable for their ability to capture context across long stretches of text. This is a significant advancement over rule-based, statistical, and traditional machine learning approaches.",
  "What is Tokenization?": "The process of breaking down a sentence into tokens, which can be individual words or parts of words.",
  "What are encoders and decoders in LLMs?": "This process handles the input text to create a representation format that captures its meaning, and generates output text based on that representation representation to produce coherent and contextually relevant output.",
  "What is the temperature parameter in LLMs?": "A hyperparameter that controls the randomness of predictions by scaling the logits before applying softmax. A higher settinng results in more random outputs, while a lower setting makes the model more deterministic.",
  "What is Rag in LLMs?": "a technique that combines retrieval of relevant information from external sources with the generation capabilities of LLMs. It enhances the model's ability to provide accurate and contextually relevant responses by incorporating external knowledge.",
  "What is the primary advantage of using Retrieval Augmented Generation (RAG) in a natural language processing system?": "It allows the model to access and incorporate external knowledge, improving the accuracy and relevance of generated responses. This is particularly useful for tasks that require up-to-date information or specialized knowledge that may not be present in the model's training data.",
  "What is Fine-Tuning Large Language Models (LLMs)": "effectively customizes it for specialized tasks, leveraging its broad learning capabilities to adapt to specific domains or industries. This process refines the model's expertise, making it highly useful for niche applications.",
  "What determines the starting point of the generative process in Stable Diffusion?": "The seed",
  "What happens when you use the same seed and the same prompt in Stable Diffusion?": "The exact same image is generated",
  "What is the primary purpose of a model card in machine learning?": "To provide transparency and governance by documenting critical information about an ML/AI model in a structured format.",
  "What section of a model card outlines scenarios where the model should or should not be used?": "Intended Use"
}
